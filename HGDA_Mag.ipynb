{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22393660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2293.1467, Source Loss: 1913.7605, Target Pseudo Loss: 331.3721, KL Loss: 48.0140, Target Test Accuracy: 0.6046\n",
      "Epoch [2/10], Loss: 2103.1468, Source Loss: 1775.2839, Target Pseudo Loss: 317.0018, KL Loss: 10.8611, Target Test Accuracy: 0.6040\n",
      "Epoch [3/10], Loss: 2049.5329, Source Loss: 1731.7040, Target Pseudo Loss: 312.1236, KL Loss: 5.7052, Target Test Accuracy: 0.6034\n",
      "Epoch [4/10], Loss: 2033.2268, Source Loss: 1719.5109, Target Pseudo Loss: 310.0321, KL Loss: 3.6838, Target Test Accuracy: 0.6056\n",
      "Epoch [5/10], Loss: 2021.8988, Source Loss: 1711.4029, Target Pseudo Loss: 307.7780, KL Loss: 2.7178, Target Test Accuracy: 0.6083\n",
      "Epoch [6/10], Loss: 1996.4462, Source Loss: 1688.5892, Target Pseudo Loss: 305.7716, KL Loss: 2.0854, Target Test Accuracy: 0.6059\n",
      "Epoch [7/10], Loss: 1998.4082, Source Loss: 1690.1747, Target Pseudo Loss: 306.7852, KL Loss: 1.4482, Target Test Accuracy: 0.6030\n",
      "Epoch [8/10], Loss: 1980.1382, Source Loss: 1675.0934, Target Pseudo Loss: 303.8192, KL Loss: 1.2256, Target Test Accuracy: 0.6067\n",
      "Epoch [9/10], Loss: 1995.1149, Source Loss: 1687.2902, Target Pseudo Loss: 306.6035, KL Loss: 1.2212, Target Test Accuracy: 0.6070\n",
      "Epoch [10/10], Loss: 1974.9382, Source Loss: 1673.1240, Target Pseudo Loss: 300.7683, KL Loss: 1.0459, Target Test Accuracy: 0.6064\n",
      "Final Target Domain Test Accuracy: 0.6064\n",
      "Final Target Domain Micro-F1: 0.6064\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix\n",
    "from pygda.datasets import AirportDataset\n",
    "from pygda.datasets import MAGDataset\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from torch_geometric.utils import to_scipy_sparse_matrix\n",
    "    from pygda.datasets import AirportDataset\n",
    "except ModuleNotFoundError as e:\n",
    "    raise ImportError(\"Please ensure all necessary libraries such as torch, pygda, and torch_geometric are installed.\") from e\n",
    "\n",
    "MAG_CN_dataset = MAGDataset('C:/Users/Administrator/Desktop/Graph DA/MAG_US', name='source')[0]\n",
    "MAG_RU_dataset = MAGDataset('C:/Users/Administrator/Desktop/Graph DA/MAG_JP', name='source')[0]\n",
    "\n",
    "\n",
    "source_dataset = MAG_CN_dataset\n",
    "target_dataset = MAG_RU_dataset\n",
    "\n",
    "\n",
    "if not hasattr(source_dataset, 'x') or not hasattr(source_dataset, 'y'):\n",
    "    raise ValueError(\"Source dataset is missing features or labels.\")\n",
    "if not hasattr(target_dataset, 'x') or not hasattr(target_dataset, 'y'):\n",
    "    raise ValueError(\"Target dataset is missing features or labels.\")\n",
    "\n",
    "if source_dataset.x is None or source_dataset.y is None:\n",
    "    raise ValueError(\"Source dataset features or labels are None.\")\n",
    "if target_dataset.x is None or target_dataset.y is None:\n",
    "    raise ValueError(\"Target dataset features or labels are None.\")\n",
    "\n",
    "\n",
    "class DomainAlignmentModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(DomainAlignmentModel, self).__init__()\n",
    "        \n",
    "\n",
    "        self.low_pass = nn.Linear(input_dim, hidden_dim)\n",
    "        self.high_pass = nn.Linear(input_dim, hidden_dim)\n",
    "        self.identity = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "\n",
    "        self.weight_low = nn.Parameter(torch.tensor(1.0))\n",
    "        self.weight_high = nn.Parameter(torch.tensor(1.0))\n",
    "        self.weight_id = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "\n",
    "        self.classifier = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        low_pass = F.relu(self.low_pass(x))\n",
    "        high_pass = F.relu(self.high_pass(x))\n",
    "        identity = F.relu(self.identity(x))\n",
    "        \n",
    "        combined = self.weight_low * low_pass + self.weight_high * high_pass + self.weight_id * identity\n",
    "        return combined, low_pass, high_pass, identity\n",
    "\n",
    "\n",
    "input_dim = source_dataset.x.size(1)\n",
    "hidden_dim = 64\n",
    "output_dim = int(source_dataset.y.max().item()) + 1\n",
    "model = DomainAlignmentModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "classification_loss_fn = nn.CrossEntropyLoss()\n",
    "kl_loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "\n",
    "source_features, source_labels = source_dataset.x, source_dataset.y\n",
    "source_data = torch.utils.data.TensorDataset(source_features, source_labels)\n",
    "source_loader = torch.utils.data.DataLoader(source_data, batch_size=32, shuffle=True)\n",
    "\n",
    "target_features, target_labels = target_dataset.x, target_dataset.y\n",
    "target_data = torch.utils.data.TensorDataset(target_features, target_labels)\n",
    "target_loader = torch.utils.data.DataLoader(target_data, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "def train(model, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_source_loss = 0\n",
    "        total_target_loss = 0\n",
    "        total_kl_loss = 0\n",
    "\n",
    "        for (src_batch, tgt_batch) in zip(source_loader, target_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Source Domain\n",
    "            src_features, src_labels = src_batch\n",
    "            src_combined, src_low, src_high, src_id = model(src_features)\n",
    "            src_logits = model.classifier(src_combined)\n",
    "            source_class_loss = classification_loss_fn(src_logits, src_labels)\n",
    "\n",
    "            # Target Domain (pseudo-labels generation and loss computation)\n",
    "            tgt_features, _ = tgt_batch\n",
    "            tgt_combined, tgt_low, tgt_high, tgt_id = model(tgt_features)\n",
    "            tgt_logits = model.classifier(tgt_combined)\n",
    "            pseudo_target_labels = tgt_logits.argmax(dim=1)  # Pseudo labels from current model predictions\n",
    "            target_class_loss = classification_loss_fn(tgt_logits, pseudo_target_labels)\n",
    "\n",
    "\n",
    "            if src_low.size(0) == tgt_low.size(0):  # Ensure batch sizes match for KL alignment\n",
    "                kl_low = kl_loss_fn(F.log_softmax(tgt_low, dim=1), F.softmax(src_low, dim=1))\n",
    "                kl_high = kl_loss_fn(F.log_softmax(tgt_high, dim=1), F.softmax(src_high, dim=1))\n",
    "                kl_id = kl_loss_fn(F.log_softmax(tgt_id, dim=1), F.softmax(src_id, dim=1))\n",
    "                kl_loss = kl_low + kl_high + kl_id\n",
    "            else:\n",
    "                kl_loss = torch.tensor(0.0, requires_grad=True)  # Handle mismatch gracefully\n",
    "\n",
    "\n",
    "            loss = source_class_loss  + kl_loss +target_class_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_source_loss += source_class_loss.item()\n",
    "            total_target_loss += target_class_loss.item()\n",
    "            total_kl_loss += kl_loss.item()\n",
    "\n",
    "\n",
    "        tgt_combined_eval, _, _, _ = model(target_features)\n",
    "        tgt_logits_eval = model.classifier(tgt_combined_eval)\n",
    "        predictions = tgt_logits_eval.argmax(dim=1)\n",
    "        test_accuracy = (predictions == target_labels).float().mean().item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Source Loss: {total_source_loss:.4f}, Target Pseudo Loss: {total_target_loss:.4f}, KL Loss: {total_kl_loss:.4f}, Target Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def test(model): \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tgt_combined, _, _, _ = model(target_features)\n",
    "        tgt_logits = model.classifier(tgt_combined)\n",
    "        predictions = tgt_logits.argmax(dim=1)\n",
    "        accuracy = (predictions == target_labels).float().mean().item()\n",
    "        \n",
    "        true_labels = target_labels.cpu().numpy()\n",
    "        pred_labels = predictions.cpu().numpy()\n",
    "        micro_f1 = f1_score(true_labels, pred_labels, average='micro')\n",
    "        \n",
    "        print(f\"Final Target Domain Test Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Final Target Domain Micro-F1: {micro_f1:.4f}\")\n",
    "\n",
    "train(model, optimizer)\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d55a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
